{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e3eb8491",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dill as pickle\n",
    "\n",
    "import re\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "\n",
    "from statistics import mean, stdev\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import spacy\n",
    "from unicodedata import normalize\n",
    "\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer, CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation,TruncatedSVD\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler,FunctionTransformer\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action = 'once')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ea73cb2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/pkg.7/python3/3.8.10/install/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"./data/train.csv\")\n",
    "# full_training = pd.read_csv(\"./data/train.csv\")\n",
    "# df = pd.DataFrame(full_training.sample(500000))\n",
    "\n",
    "#df= df_full.sample(100000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e2d1fafe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joining and Removing Features\n"
     ]
    }
   ],
   "source": [
    "# This is where you can do all your processing\n",
    "print(\"Joining and Removing Features\")\n",
    "df['Helpfulness'] = df['HelpfulnessNumerator'] / df['HelpfulnessDenominator']\n",
    "df['Helpfulness'] = df['Helpfulness'].fillna(0)\n",
    "\n",
    "df['Text'] = df['Summary']+ ' ' +df['Text'] # combine text fields \n",
    "df['Raw_text'] = df['Text']\n",
    "df['Review_len'] = df[\"Text\"].str.len() # review length\n",
    "df.drop('HelpfulnessDenominator', axis=1, inplace=True) # remove denominator field\n",
    "df.drop('HelpfulnessNumerator', axis=1, inplace=True) # remove nominator field\n",
    "df.drop('Summary', axis=1, inplace=True) # remove summary \n",
    "# df = df.dropna(subset=['Text']) # remove any empty text fields \n",
    "df.Text = df.Text.fillna('fill') # instead of getting rid of no text fields, fill with word \"fill\"\n",
    "df.Raw_text = df.Raw_text.fillna('fill') # instead of getting rid of no text fields, fill with word \"fill\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b43435cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add time review was posted \n",
    "# Month may not add much infor\n",
    "\n",
    "df['Date'] = pd.to_datetime(df['Time'], unit='s')\n",
    "df['Month'] = df['Date'].dt.month\n",
    "df['Year'] = df['Date'].dt.year\n",
    "\n",
    "df.drop('Date', axis=1, inplace=True) # remove date field\n",
    "df.drop('Time', axis=1, inplace=True) # remove Time field\n",
    "# df.drop('Month', axis=1, inplace=True) # remove Month field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ec2d626d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binning Years\n"
     ]
    }
   ],
   "source": [
    "print(\"Binning Years\")\n",
    "df['Year_bin'] = df['Year'].astype(int)\n",
    "df.loc[ df['Year'] <= 1998, 'Year_bin'] = 0 #0\n",
    "df.loc[(df['Year'] > 1998) & (df['Year'] <= 2000), 'Year_bin'] = 1 # 0\n",
    "df.loc[(df['Year'] > 2000) & (df['Year'] <= 2002), 'Year_bin'] = 2 # 1\n",
    "df.loc[(df['Year'] > 2002) & (df['Year'] <= 2004), 'Year_bin'] = 3 # 1\n",
    "df.loc[(df['Year'] > 2004) & (df['Year'] <= 2006), 'Year_bin'] = 4 # 2\n",
    "df.loc[(df['Year'] > 2006) & (df['Year'] <= 2008), 'Year_bin'] = 5 # 2\n",
    "df.loc[(df['Year'] > 2008) & (df['Year'] <= 2010), 'Year_bin'] = 6 # 2\n",
    "df.loc[(df['Year'] > 2010) & (df['Year'] <= 2012), 'Year_bin'] = 7 # 3\n",
    "df.loc[(df['Year'] > 2012) & (df['Year'] <= 2014), 'Year_bin'] = 8 # 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "095636f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binning Months\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/pkg.7/python3/3.8.10/install/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# 0,1,2,3,4,5,6,7,8,9,10,11,12\n",
    "#\n",
    "#winter: 0, spring: 0.33, summer: 0.66, fall: 1\n",
    "print(\"Binning Months\")\n",
    "df['Season'] = df['Month'].astype(int)\n",
    "df.loc[(df['Month'] > 11 ) & (df['Month'] <= 2), 'Season'] = 0 # winter\n",
    "df.loc[(df['Month'] > 2) & (df['Month'] <= 5), 'Season'] = .33 # spring\n",
    "df.loc[(df['Month'] > 5) & (df['Month'] <= 8), 'Season'] = .66 # summer\n",
    "df.loc[(df['Month'] > 8) & (df['Month'] <= 11), 'Season'] = 1 # Fall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2ba228f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/pkg.7/python3/3.8.10/install/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading nltk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package names to\n",
      "[nltk_data]     /usr4/ugrad/arnaudh/nltk_data...\n",
      "[nltk_data]   Package names is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /usr4/ugrad/arnaudh/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /usr4/ugrad/arnaudh/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /usr4/ugrad/arnaudh/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /usr4/ugrad/arnaudh/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /usr4/ugrad/arnaudh/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /usr4/ugrad/arnaudh/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"downloading nltk\")\n",
    "# download nltk tools\n",
    "nltk.download([\n",
    "\"names\",\n",
    "\"stopwords\",\n",
    "\"averaged_perceptron_tagger\",\n",
    "\"wordnet\",\n",
    "'omw-1.4',\n",
    "\"vader_lexicon\",\n",
    "\"punkt\",])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ea7658ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Text Data\n"
     ]
    }
   ],
   "source": [
    "print(\"Processing Text Data\")\n",
    "# remove any non A-Z characters in review text\n",
    "regex = re.compile('[^a-zA-Z]')\n",
    "df['Text'] = df['Text'].apply(lambda x: regex.sub(\" \", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a3cec73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing Stopwords\n"
     ]
    }
   ],
   "source": [
    "print(\"Removing Stopwords\")\n",
    "# function for removing all stopwords from a piece of text \n",
    "stopwords=nltk.corpus.stopwords.words(\"english\")\n",
    "def rem_stopw(words):\n",
    "    words = [w for w in words if w.lower() not in stopwords]\n",
    "    return words\n",
    "\n",
    "#remove stopwords from the text in df \n",
    "df['Text'] = df['Text'].apply(lambda x: nltk.word_tokenize(x))\n",
    "df['Text'] = df['Text'].apply(lambda x: rem_stopw(x)) #remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9a49996a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-join the tokenized texrt so that VADER can work properly\n",
    "df['Text'] = df['Text'].apply(lambda x:\" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "64f264c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing Sentiment Analysis\n"
     ]
    }
   ],
   "source": [
    "#SIA works on raw text, not anything tokenized, hence the above operation\n",
    "print(\"Performing Sentiment Analysis\")\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "def sentiment(text):\n",
    "    scores = []\n",
    "    #all_scores = []\n",
    "    for sentence in nltk.sent_tokenize(text):\n",
    "        scores.append(sia.polarity_scores(sentence)[\"compound\"])\n",
    "        #all_scores.append(sia.polarity_scores(sentence))\n",
    "    try:\n",
    "        scores = mean(scores)\n",
    "    except:\n",
    "        scores = np.nan\n",
    "    \n",
    "    return scores\n",
    "\n",
    "# add sentiment score to dataframe\n",
    "df['Sentiment'] = df['Text'].apply(lambda x: sentiment(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "05488437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing Numerical Data\n"
     ]
    }
   ],
   "source": [
    "# NORMALIZE NUMERICAL DATA\n",
    "print('Normalizing Numerical Data')\n",
    "def scale_col(col):\n",
    "    return (col - col.min()) / (col.max() - col.min())\n",
    "df['Review_len'] = scale_col(df['Review_len'])\n",
    "df['Month'] = scale_col(df['Month'])\n",
    "# df['Season'] = scale_col(df['Season'])\n",
    "df['Year_bin'] = scale_col(df['Year_bin'])\n",
    "df['Year'] = scale_col(df['Year'])\n",
    "df['Sentiment'] = scale_col(df['Sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1abaa495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test set\n",
    "submissionSet = pd.read_csv(\"./data/test.csv\")\n",
    "\n",
    "# Merge on Id so that the test set can have feature columns as well\n",
    "testX= pd.merge(df, submissionSet, left_on='Id', right_on='Id')\n",
    "testX = testX.drop(columns=['Score_x'])\n",
    "testX = testX.rename(columns={'Score_y': 'Score'})\n",
    "\n",
    "# The training set is where the score is not null\n",
    "trainX =  df[df['Score'].notnull()]\n",
    "\n",
    "testX.to_csv(\"./data/X_test.csv\", index=False)\n",
    "trainX.to_csv(\"./data/X_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e63005",
   "metadata": {},
   "source": [
    "##############################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2e2b2e",
   "metadata": {},
   "source": [
    "######################################## MODELS ##############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "540e18e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-40-d02564e73f4b>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  trainX['Text']= trainX['Text'].fillna('fill')\n"
     ]
    }
   ],
   "source": [
    "trainX['Text']= trainX['Text'].fillna('fill')\n",
    "trainX['Raw_text']= trainX['Raw_text'].fillna('fill')\n",
    "trainX['Sentiment']= trainX['Sentiment'].fillna(trainX['Sentiment'].mean())\n",
    "trainX['Review_len']=trainX['Review_len'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dafc4671",
   "metadata": {},
   "outputs": [],
   "source": [
    "testX['Text'] = testX['Text'].fillna('fill')\n",
    "testX['Raw_text']= testX['Raw_text'].fillna('fill')\n",
    "testX['Review_len']=testX['Review_len'].fillna(0)\n",
    "testX['Sentiment']= testX['Sentiment'].fillna(testX['Sentiment'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "34d40520",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_submission = testX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "176a6c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_submission['Text']= X_submission['Text'].fillna('fill')\n",
    "X_submission['Raw_text']= X_submission['Raw_text'].fillna('fill')\n",
    "X_submission['Review_len']=X_submission['Review_len'].fillna(0)\n",
    "X_submission['Sentiment']= X_submission['Sentiment'].fillna(X_submission['Sentiment'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4cc1b640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load files into DataFrames\n",
    "#X_train = pd.read_csv(\"./data/X_train.csv\")\n",
    "\n",
    "X_train = trainX\n",
    "\n",
    "\n",
    "# Split training set into training and testing set\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "        X_train.drop(['Score'], axis=1),\n",
    "        X_train['Score'],\n",
    "        test_size=1/4.0,\n",
    "        random_state=0\n",
    "    )\n",
    "\n",
    "# This is where you can do more feature selection\n",
    "X_train_processed =  X_train.drop(columns=['Id', 'ProductId', 'UserId', 'Text'])\n",
    "X_test_processed = X_test.drop(columns=['Id', 'ProductId', 'UserId', 'Text'])\n",
    "X_submission_processed = X_submission.drop(columns=[\n",
    "    'Id', 'ProductId', 'UserId', 'Score', 'Text'])\n",
    "# X_submission_processed = X_test_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7d16940c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply pipeline union "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5495f766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Helpfulness    0\n",
       "Raw_text       0\n",
       "Review_len     0\n",
       "Month          0\n",
       "Year           0\n",
       "Year_bin       0\n",
       "Season         0\n",
       "Sentiment      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_processed.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ce5f4df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_text_data = FunctionTransformer(lambda x: x['Raw_text'], validate=False)\n",
    "get_numeric_data = FunctionTransformer(lambda x:\n",
    "                                       x[['Helpfulness',\n",
    "                                          'Review_len',\n",
    "                                          'Season',\n",
    "                                          'Month',\n",
    "                                          'Year',\n",
    "                                          'Year_bin',\n",
    "                                          'Sentiment',\n",
    "                                         ]], validate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9606e012",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_and_join_features = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "            ('numeric_features', Pipeline([\n",
    "                ('selector', get_numeric_data)\n",
    "            ])),\n",
    "             ('text_features', Pipeline([\n",
    "                ('selector', get_text_data),\n",
    "                 ('vec', CountVectorizer(ngram_range=(1,3)))\n",
    "            ]))\n",
    "         ])),\n",
    "    ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13016ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/pkg.7/python3/3.8.10/install/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/share/pkg.7/python3/3.8.10/install/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/share/pkg.7/python3/3.8.10/install/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/share/pkg.7/python3/3.8.10/install/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "_ = process_and_join_features.fit(X_train_processed, Y_train)\n",
    "\n",
    "pred_joined = process_and_join_features.predict(X_test_processed)\n",
    "\n",
    "print(\"LogReg Accuracy: \", np.mean(pred_joined == Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0d839abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg Accuracy:  0.6785657042108396\n"
     ]
    }
   ],
   "source": [
    "print(\"LogReg Accuracy: \", np.mean(pred_joined == Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cec5cd4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/pkg.7/python3/3.8.10/install/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "X_submission['Score'] = process_and_join_features.predict(X_submission_processed)\n",
    "submission = X_submission[['Id', 'Score']]\n",
    "submission.to_csv(\"./data/submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6829d68f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/pkg.7/python3/3.8.10/install/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "with open ('pred_LR', 'wb') as files:\n",
    "    pickle.dump(process_and_join_features, files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c2ed199a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('pred_LR', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a75a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_pred = model.predict(X_test_processed)\n",
    "\n",
    "print(\"LogReg Accuracy: \", np.mean( m_pred == Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc115662",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
